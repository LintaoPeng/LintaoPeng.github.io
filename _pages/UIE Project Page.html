<!DOCTYPE html>
<!-- saved from url=(0050)http://www.liuyebin.com/localtrans/localtrans.html -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>UIE Project Page</title>
<!-- Bootstrap -->
<link href="./UIE Project Page_files/bootstrap-4.0.0.css" rel="stylesheet">
</head>
<body data-new-gr-c-s-check-loaded="14.1036.0" data-gr-ext-installed="">
<div id="page_container">
<header>
  <div class="jumbotron">
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h5 class="text-center">2021</h5>
          <h2 class="text-center"> U-shape Transformer for Underwater Image Enhancement</h2>
          <p class="text-center">&nbsp;</p>
          <h6 class="text-center"><a href="https://lintaopeng.github.io/">Lintao Peng</a>, Chunli Zhu, <a href="https://bianlab.github.io/">Liheng Bian<sup>*</sup></a></h6>
          <p class="text-center"><sup>1</sup>Beijing Institute of Technology </p>
        </div>
      </div>
    </div>
  </div>
</header>
<section>


  <div class="container">
    <p>&nbsp;</p>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Abstract</h2>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center  offset-xl-0 col-xl-12">
        <p class="text-left"><em>The light absorption and scattering of underwater impurities lead to poor underwater imaging quality. The existing data-driven based underwater image enhancement (UIE) techniques suffer from the lack of a large-scale dataset containing various underwater scenes and high-fidelity reference images. Besides, the inconsistent attenuation in different color channels and space areas is not fully considered for boosted enhancement. In this work, we constructed a large-scale underwater image (LSUI) dataset including 4279 image pairs, and reported an U-shape Transformer network where the transformer model is for the first time introduced to the UIE task. The U-shape Transformer is integrated with a channel-wise multi-scale feature fusion transformer (CMSFFT) module and a spatial-wise global feature modeling transformer (SGFMT) module, which reinforce the network's attention to the color channels and space areas with more serious attenuation. Meanwhile, in order to further improve the contrast and saturation, a novel loss function combining RGB, LAB and LCH color spaces is designed following the human vision principle. The extensive experiments on available datasets validate the state-of-the-art performance of the reported technique with more than 2dB superiority.</em></p>
        <p class="text-left">&nbsp;</p>
        <h5 class="text-center">
          <a href="https://arxiv.org/abs/2111.11843">[arXiv]</a>
          <a href="https://github.com/LintaoPeng/U-shape_Transformer">[Code]</a>
          <a href="https://github.com/LintaoPeng/U-shape_Transformer_for_Underwater_Image_Enhancement">[Data]</a>
        </h5>
      </div>
    </div>

      <hr>
      <div class="container">
    <p>&nbsp;</p>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Highlights</h2>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center  offset-xl-0 col-xl-12">
        <p class="text-left"><em>
          1. We reported a novel U-shape Transformer dealing with the UIE task, in which the designed channel-wise and spatial-wise attention mechanism enables to effectively remove color artifacts and casts. <br>

          2. We designed a novel multi-color space loss function combing the RGB, LCH and LAB color-space features, which further improves the contrast and saturation of output images. <br>

          3. We released a large-scale underwater dataset containing 4279 image pairs, which facilitates further development of underwater imaging techniques.<br>

          4. Extensive experiments have show that the U-shape transformer we proposed combined with the multi-color space loss function achieves state-of-the-art performance on several public datasets and our dataset.<br>
        </em></p>
        <p class="text-left">&nbsp;</p>
      </div>
    </div>
      

    <hr>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">     
        <h2><a href="https://drive.google.com/file/d/10gD4s12uJxCHcuFdX9Khkv37zzBwNFbL/view?usp=sharing">[LSUI Dataset]</a> </h2>
        <p>&nbsp;</p>
      </div>

    </div>
    <div class="row">
        <div class="col-lg-12 col-md-12 col-sm-12 text-center col-xl-12"> <img src="./UIE Project Page_files/data.png" width="1000" alt="" >
          <p>&nbsp;</p>
          <p class="text-left">We released a large-scale dataset(LSUI) containing 4279 real underwater images and the corresponding high-quality reference images, semantic segmentation maps, and medium transmission maps, which involve richer underwater scenes (lighting conditions, water types and target categories) and facilitates further development of UIE techniques. You can download it from [BaiduYun](https://pan.baidu.com/s/1dqB_k6agorQBVVqCda0vjA)(password is lsui) or [GoogleDrive](https://drive.google.com/file/d/10gD4s12uJxCHcuFdX9Khkv37zzBwNFbL/view?usp=sharing). If you want to use the LSUI dataset, please cite our [[paper\]](https://ieeexplore.ieee.org/abstract/document/10129222)
</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
      </div>
    </div>


      
    <hr>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">     
        <h2>Overall Architecture </h2>
        <p>&nbsp;</p>
      </div>

    </div>
    <div class="row">
        <div class="col-lg-12 col-md-12 col-sm-12 text-center col-xl-12"> <img src="./UIE Project Page_files/2.png" width="1000" alt="" >
          <p>&nbsp;</p>
          <p class="text-left">Fig 1. Detailed network structure. The model is modified based on Unet-Gan. In order to guide the network to pay attention to the more severely attenuated color channels and spatial regions, we introduced the CMSFFT module and SGFMT module based on transformer architecture . In order to make the training process of our nodel more stable, we added a multi-scale gradient flow mechanism to the network.</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
      </div>
    </div>
     


    <hr> 
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Detailed structure of SGFMT and CMSFFT </h2>
        <p>&nbsp;</p>
      </div>
    </div>

    
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center col-xl-12"> <img src="./UIE Project Page_files/3.png" width="1000" alt="" align="center">
        <p>&nbsp;</p>
        <p class="text-center">Fig 2. SGFMT data flow diagram.</p>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
      </div>
    </div>

    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center col-xl-12"> <img src="./UIE Project Page_files/4.png" width="1000" alt="" align="center">
        <p>&nbsp;</p>
        <p class="text-center">Fig 3. CMSFFT detailed structure</p>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
      </div>
    </div>



      
    <hr> 
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Results </h2>
        <p>&nbsp;</p>
      </div>
    </div>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center col-xl-12"> <img src="./UIE Project Page_files/5.png" width="1000" alt="">
        <p>&nbsp;</p>
        <p class="text-center">Fig 4. Enhancement results of U-shape transformer trained on different underwater datasets. (a): Underwater images sampled from Test-L504; (b): Enhanced results using the model trained on the underwater dataset Train-U2050; (c): Enhanced results using the model trained on the underwater dataset Train-E11435; (d): Enhanced results using the model trained by our proposed dataset Train-L4500; (e): References images (Regarded as Ground Truth)</p>
        <p>&nbsp;</p>
      </div>
    </div>


    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center col-xl-12"> <img src="./UIE Project Page_files/6.png" width="1000" alt="">
        <p>&nbsp;</p>
        <p class="text-center">Fig 5. Visual comparison of enhancement results sampled from Test-L504. From left to right are raw images, and the results of UIBLA, Retinex based, FUnLE, UGAN, UIE-DAL, Ucolor, and our U-shape Transformer.</p>
        <p>&nbsp;</p>
      </div>
    </div>

    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center col-xl-12"> <img src="./UIE Project Page_files/7.png" width="1000" alt="">
        <p>&nbsp;</p>
        <p class="text-center">Fig 6. Visual comparison of enhancement results sampled from Test-U60. From left to right are raw images, and the results of UIBLA , Retinex based, FUnLE, UGAN, UIE-DAL, Ucolor, and our U-shape Transformer.</p>
        <p>&nbsp;</p>
      </div>
    </div>




    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center col-xl-12"> <img src="./UIE Project Page_files/8.png" width="500" alt="">
        <p>&nbsp;</p>
        <p class="text-center">Tab 7. Evaluation with Reference Images on Test-L504 and Test-U90</p>
        <p>&nbsp;</p>
      </div>
    </div>

    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center col-xl-12"> <img src="./UIE Project Page_files/9.png" width="1000" alt="">
        <p>&nbsp;</p>
        <p class="text-center">Tab 8. Evaluation without Reference Images on Test-U60 and SQUID</p>
        <p>&nbsp;</p>
      </div>
    </div>


    <hr>  
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Technical Paper</h2>
      </div>
    </div>
    <p>&nbsp;</p>
    <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center"> <a href="https://arxiv.org/abs/2111.11843"><img src="./UIE Project Page_files/10.png" width="1000" alt=""></a>
      <p>&nbsp;</p>
    </div>
    <hr>


    <div class="row">
      <div class="col-lg-12 mb-4 mt-2 text-center">
        <h2>Demo Video</h2>
      </div>
    </div>
    <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
      <video controls="controls" width="1024" height="576">
        <source src="./UIE Project Page_files/supplementary_video.mp4" type="video/mp4">
      </video>
      <p>&nbsp;</p>
    </div>
	<hr>


    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Citation</h2>
      </div>
    </div>
    <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-left">
      <p><span style="color:#000000;font-family:&#39;Courier New&#39;;font-size:15px;"> 
		Lintao Peng, Chunli Zhu, and Liheng Bian. "U-shape Transformer
		for Underwater Image Enhancement", 2021
      </span></p>
      <p>&nbsp;</p>
      <p><span style="color:#000000;font-family:&#39;Courier New&#39;;font-size:15px;">
		@misc{peng2021ushape,<br>
		title={U-shape Transformer for Underwater Image Enhancement}, <br>
		author={Lintao Peng and Chunli Zhu and Liheng Bian},<br>
		year={2021},<br>
		eprint={2111.11843},<br>
		archivePrefix={arXiv},<br>
		primaryClass={cs.CV}<br>
		}
		  </span></p>
      <p>&nbsp;</p>
      <p>&nbsp;</p>
    </div>
    <div class="row"> </div>
  </div>
  <div class="jumbotron"> </div>

</div></section>	
</div>

<!-- jQuery (necessary for Bootstrap's JavaScript plugins) --> 
<script src="./UIE Project Page_files/jquery-3.2.1.min.js.下载"></script> 
<!-- Include all compiled plugins (below), or include individual files as needed --> 
<script src="./UIE Project Page_files/popper.min.js.下载"></script> 
<script src="./UIE Project Page_files/bootstrap-4.0.0.js.下载"></script>

</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>
